> # 41. Identifying Bias, Variance, and Data Mismatch Errors

--> _replace THIS LINE by your translation for the above line_


> Suppose humans achieve almost perfect performance (≈0% error) on the cat detection task, and thus the optimal error rate is about 0%. Suppose you have:

--> _replace THIS LINE by your translation for the above line_

> * 1% error on the training set.

--> _replace THIS LINE by your translation for the above line_


> * 5% error on training dev set.

--> _replace THIS LINE by your translation for the above line_


> * 5% error on the dev set.

--> _replace THIS LINE by your translation for the above line_

> What does this tell you? Here, you know that you have high variance. The variance reduction techniques described earlier should allow you to make progress.

--> _replace THIS LINE by your translation for the above line_


> Now, suppose your algorithm achieves:

--> _replace THIS LINE by your translation for the above line_


> * 10% error on the training set.

--> _replace THIS LINE by your translation for the above line_


> * 11% error on training dev set.

--> _replace THIS LINE by your translation for the above line_


> * 12% error on the dev set.

--> _replace THIS LINE by your translation for the above line_


> This tells you that you have high avoidable bias on the training set. I.e., the algorithm is doing poorly on the training set. Bias reduction techniques should help.

--> _replace THIS LINE by your translation for the above line_


> In the two examples above, the algorithm suffered from only high avoidable bias or high variance. It is possible for an algorithm to suffer from any subset of high avoidable bias, high variance, and data mismatch. For example:

--> _replace THIS LINE by your translation for the above line_


> * 10% error on the training set.

--> _replace THIS LINE by your translation for the above line_


> * 11% error on training dev set.

--> _replace THIS LINE by your translation for the above line_


> * 20% error on the dev set.

--> _replace THIS LINE by your translation for the above line_


> This algorithm suffers from high avoidable bias and from data mismatch. It does not, however, suffer from high variance on the training set distribution.

--> _replace THIS LINE by your translation for the above line_


> It might be easier to understand how the different types of errors relate to each other by drawing them as entries in a table:

--> _replace THIS LINE by your translation for the above line_


![img](../imgs/C41_01.png)

> Continuing with the example of th​e cat image detector, you can see that there are two different distributions of data on the x-axis. On the y-axis, we ha​ve three types of error: human level error, error on examples the algorithm has trained on, and error on examples the algorithm has not trained on. We can fill in the boxes with the different types of errors we identified in the previous chapter.

--> _replace THIS LINE by your translation for the above line_


> If you wish, you can also fill in the remaining two boxes in this table: You can fill in the upper-right box (Human level performance on Mobile Images) by asking some humans to label your mobile cat images data and measure their error. You can fill in the next box by taking the mobile cat images (Distribution B) and putting a small fraction of into the training set so that the neural network learns on it too. Then you measure the learned model’s error on that subset of data. Filling in these two additional entries may sometimes give additional insight about what the algorithm is doing on the two different distributions (Distribution A and B) of data.

--> _replace THIS LINE by your translation for the above line_


> By understanding which types of error the algorithm suffers from the most, you will be better positioned to decide whether to focus on reducing bias, reducing variance, or reducing data mismatch.

--> _replace THIS LINE by your translation for the above line_

