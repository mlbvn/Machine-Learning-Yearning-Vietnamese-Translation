> # 45. General form of Optimization Verification test

-> _start your translation RIGHT AFTER this line_

> You can apply the Optimization Verification test when, given some input ​*x​*, you know how to compute Score​<sub>x</sub>​(*y​*) that indicates how good a response ​*y​* is to an input ​*x*.​ Furthermore, you are using an approximate algorithm to try to find arg max​<sub>y</sub>​ Score​<sub>x</sub>​(*y​*), but suspect that the search algorithm is sometimes failing to find the maximum. In our previous speech recognition example, ​*x=A​* was an audio clip, and ​*y=S​* was the output transcript.

-> _start your translation RIGHT AFTER this line_

> Suppose y* is the “correct” output but the algorithm instead outputs y​<sub>out</sub>​. Then the key test is out​ o measure whether Score​<sub>x</sub>​(y*) > Score​<sub>x</sub>​(y​<sub>out</sub>). If this inequality holds, then we blame the x​ x​ out​ optimization algorithm for the mistake. Refer to the previous chapter to make sure you understand the logic behind this. Otherwise, we blame the computation of Score​<sub>x</sub>​(y).

-> _start your translation RIGHT AFTER this line_
> Let’s look at one more example. Suppose you are building a Chinese-to-English machine
> translation system. Your system works by inputting a Chinese sentence ​*C*,​ and computing
> some Score​<sub>C</sub>​(​*E*)​ for each possible translation ​E.​ For example, you might use Score​<sub>C</sub>​(​*E*)​ = P(*E*|*C*), the probability of the translation being E given that the input sentence was ​*C*.

-> _start your translation RIGHT AFTER this line_
> Your algorithm translates sentences by trying to compute:

-> _start your translation RIGHT AFTER this line_

> However, the set of all possible English sentences ​*E* i​ s too large, so you rely on a heuristic search algorithm.

-> _start your translation RIGHT AFTER this line_
> Suppose your algorithm outputs an incorrect translation ​*E​*<sub>out</sub>​ rather than some correct translation ​E​*. Then the Optimization Verification test would ask you to compute whether Score​<sub>C</sub>​(*E**) > Score​<sub>C</sub>​(*E*<sub>out</sub>). If this inequality holds, then the Score​<sub>C</sub>​(.) correctly recognized E* as a superior output to *E​*<sub>out</sub>​; thus, you would attribute this error to the approximate search algorithm. Otherwise, you attribute this error to the computation of Score​<sub>C</sub>​(.).

-> _start your translation RIGHT AFTER this line_
> It is a very common “design pattern” in AI to first learn an approximate scoring function
> Score​<sub>x</sub>​(.), then use an approximate maximization algorithm. If you are able to spot this pattern, you will be able to use the Optimization Verification test to understand your source of errors.

-> _start your translation RIGHT AFTER this line_