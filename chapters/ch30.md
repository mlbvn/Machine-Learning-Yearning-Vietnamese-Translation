> # 30. Interpreting learning curves: High bias

--> # 30. Giải thích đường cong học tập: Độ lệch cao

> Suppose your dev error curve looks like this:

--> Giả sử đường cong lỗi phát triển của bạn trông như thế này:

![img](../imgs/C30_01.png)

> We previously said that, if your dev error curve plateaus, you are unlikely to achieve the desired performance just by adding data.

--> Chúng ta đã đề cập trước đây rằng, nếu đường cong lỗi phát triển của bạn trở nên bằng phẳng, bạn không hẳn đạt được chất lượng mong đợi chỉ bằng việc thêm vào dữ liệu.

> But it is hard to know exactly what an extrapolation of the red dev error curve will look like. If the dev set was small, you would be even less certain because the curves could be noisy.

--> Nhưng thật khó để biết chính xác một ngoại suy của đường cong lỗi phát triển màu đỏ sẽ trông như thế nào. Nếu tập phát triển là nhỏ, bạn sẽ càng không chắc chắn bởi vì các đường cong có thể bị nhiễu.

> Suppose we add the training error curve to this plot and get the following:

--> Giả sử chúng ta thêm vào đường cong lỗi huấn luyện vào biểu đồ này và có được như sau:

![img](../imgs/C30_02.png)

> Now, you can be absolutely sure that adding more data will not, by itself, be sufficient. Why is that? Remember our two observations:

--> Bây giờ, bạn có thể hoàn toàn chắc chắn rằng chỉ thêm nhiều dữ liệu là không đủ. Tại sao như thế? Nhớ rằng hai quan sát của chúng ta:

> * As we add more training data, training error can only get worse. Thus, the blue training error curve can only stay the same or go higher, and thus it can only get further away from the (green line) level of desired performance.

--> * Như chúng ta thêm nhiều dữ liệu huấn luyện, lỗi huấn luyện chỉ có thể kém hơn. Như vậy, đường cong lỗi huấn luyện màu xanh dương có thể chỉ giữ nguyên hoặc tăng cao hơn, và như vậy nó chỉ có thể trở nên xa hơn khỏi mức chất lượng mong đợi (đường màu xanh lục).


> * The red dev error curve is usually higher than the blue training error. Thus, there’s almost no way that adding more data would allow the red dev error curve to drop down to the desired level of performance when even the training error is higher than the desired level of performance.

--> *Đường cong lỗi phát triển màu đỏ thường cao hơn lỗi huấn luyện màu xanh dương. Như vậy, ở đây hầu như không có khả năng rằng thêm vào nhiều dữ liệu sẽ làm cho đường cong lỗi phát triển màu đỏ giảm xuống đến mức độ chất lượng mong đợi khi ngay cả lỗi huẩn luyện còn cao hơn mức độ chất lượng mong đợi.


> Examining both the dev error curve and the training error curve on the same plot allows us to more confidently extrapolate the dev error curve.

--> Việc kiểm tra cả hai đường cong lỗi phát triển và lỗi huẩn luyện trên cùng một biểu đồ cho phép chúng ta ngoại suy tự tin hơn đường cong lỗi phát triển.


> Suppose, for the sake of discussion, that the desired performance is our estimate of the optimal error rate. The figure above is then the standard “textbook” example of what a learning curve with high avoidable bias looks like: At the largest training set size—presumably corresponding to all the training data we have—there is a large gap between the training error and the desired performance, indicating large avoidable bias. Furthermore, the gap between the training and dev curves is small, indicating small variance.

--> Giả sử, cho sự thảo luận, rằng chất lượng mong đợi là ước lượng của chúng ta về mức độ lỗi tối ưu. Hình vẽ trên khi đó là một ví dụ tiêu chuẩn "giáo khoa" của cái mà một đường cong học tập với độ lệch tránh được cao trong như thế nào: Ở tập huấn luyện cỡ lớn nhất - có lẻ tương ứng với tấp cả các dữ liệu huấn luyện ta có - ở đây có một khoảng trống lớn giữa lỗi huấn luyện và chất lượng mong đợi, biểu thị độ lệch tránh được lớn. Hơn thế nữa, khoảng trống giữa đường cong huấn luyện và phát triển nhỏ, biểu thị cho phương sai nhỏ.


> Previously, we were measuring training and dev set error only at the rightmost point of this plot, which corresponds to using all the available training data. Plotting the full learning curve gives us a more comprehensive picture of the algorithms’ performance on different training set sizes.

--> Trước đó, chúng ta đo lường lỗi tập huấn luyện và tập phát triển chỉ ở điểm ngoài cùng bên phải của biểu đồ này, cái tương ứng với sử dụng tất cả dữ liệu huấn luyện sẵn có. Việc vẽ biểu đồ toàn đường cong học tập cho chúng ta một bức tranh toàn diện hơn về chất lượng giải thuật trên các kích cỡ tập huấn luyện khác nhau.
