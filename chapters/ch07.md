# How large do the dev/test sets need to be?

->
# Tập phát triển/kiểm tra cần lớn đến mức nào?

The dev set should be large enough to detect differences between algorithms that you are trying out. For example, if classifier A has an accuracy of 90.0% and classifier B has an accuracy of 90.1%, then a dev set of 100 examples would not be able to detect this 0.1% difference. Compared to other machine learning problems I’ve seen, a 100 example dev set is small. Dev sets with sizes from 1,000 to 10,000 examples are common. With 10,000 examples, you will have a good chance of detecting an improvement of 0.1%. [2]

->
Để nhận ra sự khác biệt giữa các thuật toán đang thử nghiệm, thì tập phát triển phải đủ lớn. Ví dụ: nếu bộ phân loại A có độ chính xác 90,0% và bộ phân loại B có độ chính xác 90,1%, thì một tập phát thiển có 100 mẫu sẽ không thể phát hiện sự khác biệt 0,1% này. So với các vấn đề khác trong machine learning mà tôi đã thấy, một tập phát triển chỉ với 100 mẫu là nhỏ. Các tập phát triển thường có từ 1,000 tới 10,000 mẫu. Với 10.000 mẫu, bạn sẽ có thể thấy sự cải thiện ở mức 0,1%. [2]

For mature and important applications—for example, advertising, web search, and product recommendations—I have also seen teams that are highly motivated to eke out even a 0.01% improvement, since it has a direct impact on the company’s profits. In this case, the dev set could be much larger than 10,000, in order to detect even smaller improvements.

->
Trong các ứng dụng quan trọng và đã đã đưa vào khai thác - lấy ví dụ như quảng cáo, tìm kiếm trên web và gợi ý sản phẩm - tôi đã thấy nhiều nhóm rất muốn cải thiện chất lượng thuật toán dù chỉ là 0,01%, vì nó có ảnh hưởng trực tiếp đến lợi ích của công ty. Trong trường hợp này, tập phát triển có thể lớn hơn 10.000 mẫu rất nhiều chỉ để đạt mức cải tiến còn nhỏ hơn nữa.

How about the size of the test set? It should be large enough to give high confidence in the overall performance of your system. One popular heuristic had been to use 30% of your data for your test set. This works well when you have a modest number of examples—say 100 to 10,000 examples. But in the era of big data where we now have machine learning problems with sometimes more than a billion examples, the fraction of data allocated to dev/test sets has been shrinking, even as the absolute number of examples in the dev/test sets has been growing. There is no need to have excessively large dev/test sets beyond what is needed to evaluate the performance of your algorithms.

->
Vậy còn kích thước của tập kiểm tra thì sao? Nó cần đủ lớn để mang lại độ tin cậy cao về hiệu năng tổng thể của hệ thống. Với tập dữ liệu khiêm tốn từ 100 tới 10.000 mẫu, thì dùng 30% dữ liệu làm tập kiểm tra là một quy tắc thực nghiệm khá phổ biến. Nhưng trong kỷ nguyên big data, khi có những bài toán machine learning đôi khi có hơn một tỷ mẫu, tỷ lệ cho các tập phát triển/kiểm tra đã bị thu hẹp lại, mặc dù số lượng mẫu trong tập phát triển/kiểm tra vẫn tăng lên. Thực sự không cần tỷ lệ tập phát triển/kiểm tra lớn hơn mức cần thiết - mức đánh giá hiệu năng chất lượng thuật toán.

**FOOTNOTE:**

[2] In theory, one could also test if a change to an algorithm makes a statistically significant difference on the dev set. In practice, most teams don’t bother with this (unless they are publishing academic research papers), and I usually do not find statistical significance tests useful for measuring interim progress.

->
**CHÚ THÍCH:**
[2] Trên lý thuyết, ta cũng có thể kiểm tra xem một thay đổi trong thuật toán có tạo ra sự khác biệt có ý nghĩa thống kê trên tập phát triển hay không. Trong thực tế, hầu hết mọi người đều không quan tâm đến điều này (trừ khi họ muốn công bố các các bài báo khoa học). Tôi thường thấy các bài kiểm định độ tin cậy thống kê không mấy hữu ích trong việc đánh giá tiến độ phát triển.
