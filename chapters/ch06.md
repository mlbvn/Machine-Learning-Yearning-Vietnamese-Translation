**Chương này đã được merge nhưng cần một lần chỉnh sửa văn phong nữa. Mong các bạn đóng góp bằng cách tạo Pull Request mới.**
-----------

> # Your dev and test sets should come from the same distribution

# Tập phát triển và tập kiểm tra nên có cùng tập phân phối

<img src="../imgs/C06_01.png" width=300 align=center>

> You have your cat app image data segmented into four regions, based on your largest markets: (i) US, (ii) China, (iii) India, and (iv) Other. To come up with a dev set and a test set, say we put US and India in the dev set; China and Other in the test set. In other words, we can randomly assign two of these segments to the dev set, and the other two to the test set, right?

Ứng dụng của bạn được phân khúc thành bốn vùng theo quy mô thị trường: (i) Hoa Kỳ, (ii) Trung Quốc, (iii) Ấn Độ, và (iv) các nước Khác. Để tạo tập phát triển và tập kiểm tra, giả định là chúng ta lấy dữ liệu từ Hoa Kỳ và Ấn Độ để tạo tập phát triển; Trung Quốc và Khác để tạo tập kiểm tra. Nói cách khác, chúng ta có thể chọn ngẫu nhiên dữ liệu ảnh từ hai trong bốn khu vực trên làm tập phát triển, và hai khu vực còn lại làm tập kiểm tra. Đúng không nào?

> Once you define the dev and test sets, your team will be focused on improving dev set performance. Thus, the dev set should reflect the task you want to improve on the most: To do well on all four geographies, and not only two.

Một khi bạn đã xác định được tập phát triển và tập kiểm tra, đội nhóm của bạn sẽ tập trung cải thiện kết quả trên tập phát triển. Do đó tập phát triển nên phản ánh được việc mà bạn muốn cải thiện nhiều nhất: hoạt động tốt trên dữ liệu từ không chỉ hai mà cả bốn khu vực địa lý.

> There is a second problem with having different dev and test set distributions: There is a chance that your team will build something that works well on the dev set, only to find that it does poorly on the test set. I’ve seen this result in much frustration and wasted effort. Avoid letting this happen to you.

Vấn đề thứ hai đối với sự phân phối của tập phát triển và tập kiểm tra: Có khả năng đội nhóm của bạn xây dựng được một thứ gì đó hoạt động tốt trên tập phát triển nhưng lại kém trên tập kiểm tra. Tôi đã từng thấy điều này  dẫn đến những kết quả đáng thất vọng và lãng phí công sức ra sao . Hãy tránh để nó xảy ra với bạn.

> As an example, suppose your team develops a system that works well on the dev set but not the test set. If your dev and test sets had come from the same distribution, then you would have a very clear diagnosis of what went wrong: You have overfit the dev set. The obvious cure is to get more dev set data.

Ví dụ như, đội nhóm của bạn xây dựng một hệ thống hoạt động tốt trên tập phát triển nhưng kém trên tập kiểm tra. Nếu tập phát triển và tập kiểm tra có cùng một tập phân phối thì bạn có thể chuẩn đoán chính xác chỗ nào sai: Tập phát triển của bạn đã bị thiếu. Hiển nhiên là bạn cần bổ sung thêm dữ liệu cho tập phát triển.

> But if the dev and test sets come from different distributions, then your options are less clear. Several things could have gone wrong:

Nhưng nếu tập phát triển và tập kiểm tra được tạo từ các tập phân phối khác nhau thì việc xác định vấn đề sẽ phức tạp hơn. Rất nhiều thứ có thể sai:   
  
> 1. You had overfit to the dev set.

1. Tập phát triển của bạn bị thiếu dữ liệu.

> 2. The test set is harder than the dev set. So your algorithm might be doing as well as could be expected, and no further significant improvement is possible.

2. Dữ liệu tập kiểm tra khó phân tích hơn tập phát triển. Vì vậy thuật toán của bạn có thể xem như đã hoạt động tốt như mong đợi, và không có cải thiện đáng kể nào khác được thực hiện.

> 3. The test set is not necessarily harder, but just different, from the dev set. So what works well on the dev set just does not work well on the test set. In this case, a lot of your work to improve dev set performance might be wasted effort.

3. Tập kiểm tra có thể không khó hơn nhưng lại khác so với tập phát triển. Do đó những gì hoạt động tốt trên tập phát triển lại kém trên tập kiểm tra. Trong trường hợp này, nhiều cố gắng cải tiến hoạt động trên tập phát triển có thể trở nên lãng phí.

> Working on machine learning applications is hard enough. Having mismatched dev and test sets introduces additional uncertainty about whether improving on the dev set distribution also improves test set performance. Having mismatched dev and test sets makes it harder to figure out what is and isn’t working, and thus makes it harder to prioritize what to work on.

Nhiều vấn đề phức tạp có thể xảy ra khi làm việc với các ứng dụng machine learning. Tập phát triển và tập kiểm tra không khớp nhau dẫn đến sự không chắc chắn về việc liệu rằng cải thiện tập phát triển có giúp cải thiện hiệu quả trên tập kiểm tra hay không. Sự không khớp giữa tập phát triển và tập kiểm tra khiến cho việc tìm ra cái gì đang hoạt động cái gì không trở nên khó khăn hơn, và vì thế khó biết cần ưu tiên làm cái nào trước hơn.

> If you are working on a 3rd party benchmark problem, their creator might have specified dev and test sets that come from different distributions. Luck, rather than skill, will have a greater impact on your performance on such benchmarks compared to if the dev and test sets come from the same distribution. It is an important research problem to develop learning algorithms that are trained on one distribution and generalize well to another. But if your goal is to make progress on a specific machine learning application rather than make research progress, I recommend trying to choose dev and test sets that are drawn from the same distribution. This will make your team more efficient.

Nếu bạn đang gặp phải vấn đề về chuẩn đánh giá của bên thứ ba thì nguyên nhân có thể là do tập phát triển và tập kiểm tra được lấy từ các tập phân phối khác nhau. Nếu so sánh với trường hợp tập phát triển và tập kiểm tra đến từ cùng một tập phân phối thì kết quả này phụ thuộc nhiều vào may mắn hơn là kỹ năng của bạn. Việc phát triển các thuật toán mà mô hình được huấn luyện trên một tập phân phối rồi được phổ biến trên một tập phân phối khác là một vấn đề quan trọng trong nghiên cứu. Tuy nhiên, nếu mục tiêu của bạn là cải thiện một ứng dụng machine learning cụ thể thay vì tạo ra tiến triển trong việc nghiên cứu thì tôi khuyên bạn chọn tập phát triển và tập kiểm tra đến từ cùng một tập phân phối. Điều này giúp đội nhóm bạn làm việc hiệu quả hơn.
