# Your dev and test sets should come from the same distribution

->
# Tập phát triển và tập kiểm tra của bạn nên được tạo ra từ cùng phân phối.
![img](../imgs/C06_01.png)

You have your cat app image data segmented into four regions, based on your largest markets: (i) US, (ii) China, (iii) India, and (iv) Other. To come up with a dev set and a test set, say we put US and India in the dev set; China and Other in the test set. In other words, we can randomly assign two of these segments to the dev set, and the other two to the test set, right?

->
Bạn có một ứng dụng ảnh mèo phân khúc theo bốn thị trường lớn nhất: (i) Hoa Kỳ, (ii) Trung Quốc, (iii) Ấn Độ, và (iv) Khu vực khác. Để tạo tập phát triển và tập kiểm tra, giả định như chúng ta lấy dữ liệu từ Hoa Kỳ và Ấn Độ để tạo tập phát triển; Trung Quốc và Khu vực khác để tạo tập kiểm tra. Nói cách khác, chúng ta có thể chọn ngẫu nhiên hai trong số bốn phân khúc làm tập phát triển và hai phân khúc còn lại làm tập kiểm tra.

Once you define the dev and test sets, your team will be focused on improving dev set performance. Thus, the dev set should reflect the task you want to improve on the most: To do well on all four geographies, and not only two.

->
Một khi bạn đã phân loại tập phát triển và tập kiểm tra, đội của bạn sẽ tập trung cải thiện kết quả trên tập phát triển. Bởi vậy, tập phát triển phải đại diện tốt nhất cho dữ liệu của nhiệm vụ muốn cải thiện: Đại diện không chỉ hai mà cả bốn thị trường.

There is a second problem with having different dev and test set distributions: There is a chance that your team will build something that works well on the dev set, only to find that it does poorly on the test set. I’ve seen this result in much frustration and wasted effort. Avoid letting this happen to you.

->
Vấn đề thứ hai với việc tập phát triển và tập kiểm tra có phân phối khác nhau: Có khả năng đội của bạn xây dựng được một mô hình hoạt động tốt trên tập phát triển nhưng lại kém trên tập kiểm tra. Tôi đã rất thất vọng và lãng phí nhiều thời gian với những mô hình như vậy. Hãy tránh để điều này xảy ra với bạn.  

As an example, suppose your team develops a system that works well on the dev set but not the test set. If your dev and test sets had come from the same distribution, then you would have a very clear diagnosis of what went wrong: You have overfit the dev set. The obvious cure is to get more dev set data.

->
Ví dụ, đội của bạn phát triển một hệ thống thực thi tốt trên tập phát triển nhưng kém trên tập kiểm tra. Nếu tập phát triển và tập kiểm tra có cùng một phân phối thì bạn có thể chuẩn đoán ngay vấn đề: Bạn đã overfit tập phát triển. Cách xử lý hiển nhiên nhất đó là bổ sung thêm dữ liệu cho tập phát triển.

But if the dev and test sets come from different distributions, then your options are less clear. Several things could have gone wrong:

->
Nhưng nếu tập phát triển và tập kiểm tra được tạo từ các phân phối khác nhau thì việc chuẩn đoán vấn đề sẽ phức tạp hơn. Các vấn đề có thể xảy ra là:   

1. You had overfit to the dev set.

->
Bạn overfit tập phát triển.

2. The test set is harder than the dev set. So your algorithm might be doing as well as could be expected, and no further significant improvement is possible.

->
Tập kiểm tra khó hơn tập phát triển. Thuật toán của bạn lúc này đã làm tốt nhất và không thể cải thiện thêm, hoặc cải thiện không đáng kể.  

3. The test set is not necessarily harder, but just different, from the dev set. So what works well on the dev set just does not work well on the test set. In this case, a lot of your work to improve dev set performance might be wasted effort.

->
Tập kiểm tra có thể không khó hơn nhưng lại khác so với tập phát triển. Do đó mô hình có thể thực thi tốt trên tập phát triển nhưng lại kém trên tập kiểm tra. Trong trường hợp này việc cố gắng cải thiện tập phát triển có thể trở nên vô nghĩa.

Working on machine learning applications is hard enough. Having mismatched dev and test sets introduces additional uncertainty about whether improving on the dev set distribution also improves test set performance. Having mismatched dev and test sets makes it harder to figure out what is and isn’t working, and thus makes it harder to prioritize what to work on.

->
Nhiều vấn đề phức tạp có thể xảy ra khi làm việc với các ứng dụng machine learning. Tập phát triển và tập kiểm tra khác nhau khiến chúng ta không chắc chắn về việc nên cải thiện tập phát triển hay cải thiện tập kiểm tra cùng lúc. Tập phát triển và tập kiểm tra khác nhau cũng khiến cho việc chuẩn đoán vấn đề trở nên phức tạp hơn, nhất là trong việc lựa chọn các công việc ưu tiên cần thiết để cải thiện mô hình.

If you are working on a 3rd party benchmark problem, their creator might have specified dev and test sets that come from different distributions. Luck, rather than skill, will have a greater impact on your performance on such benchmarks compared to if the dev and test sets come from the same distribution. It is an important research problem to develop learning algorithms that are trained on one distribution and generalize well to another. But if your goal is to make progress on a specific machine learning application rather than make research progress, I recommend trying to choose dev and test sets that are drawn from the same distribution. This will make your team more efficient.

-> Nếu bạn đang làm việc cho một bên thứ 3 về vấn đề đánh giá xếp hạng, có khả năng mô hình của họ chứa các tập phát triển và tập kiểm tra có phân phối khác nhau. Điều may mắn là thay vì dựa trên kỹ năng, nó sẽ tác động đáng kể đến năng lực của mô hình trong cùng đánh giá xếp hạng so với trường hợp khi mà các tập phát triển và tập kiểm tra cùng đến từ một phân phối. Phát triển các thuật toán machine learning được huấn luyện trên một phân phối và thực thi tốt trên các phân phối khác là vấn đề quan trọng trong nghiên cứu. Tuy nhiên nếu mục tiêu của bạn là cải tiến một ứng dụng machine learning cụ thể nào đó thay vì mục đích làm nghiên cứu, tôi khuyên bạn nên chọn các tập phát triển và tập kiểm tra có chung phân phối. Điều này sẽ giúp cả nhóm làm việc hiệu quả hơn.
