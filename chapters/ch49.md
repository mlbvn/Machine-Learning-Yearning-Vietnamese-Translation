> # 49. Pros and cons of end-to-end learning

--> _replace THIS LINE by your translation for the above line_

> Consider the same speech pipeline from our earlier example:

--> _replace THIS LINE by your translation for the above line_

![img](../imgs/C49_01.png)

> Many parts of this pipeline were "hand-engineered":

--> _replace THIS LINE by your translation for the above line_

> * MFCCs are a set of hand-designed audio features. Although they provide a reasonable summary of the audio input, they also simplify the input signal by throwing some information away.

--> _replace THIS LINE by your translation for the above line_

> * Phonemes are an invention of linguists. They are an imperfect representation of speech sounds. To the extent that phonemes are a poor approximation of reality, forcing an algorithm to use a phoneme representation will limit the speech system’s performance.

--> _replace THIS LINE by your translation for the above line_

> These hand-engineered components limit the potential performance of the speech system. However, allowing hand-engineered components also has some advantages:

--> _replace THIS LINE by your translation for the above line_

> * The MFCC features are robust to some properties of speech that do not affect the content, such as speaker pitch. Thus, they help simplify the problem for the learning algorithm.

--> _replace THIS LINE by your translation for the above line_

> * To the extent that phonemes are a reasonable representation of speech, they can also help the learning algorithm understand basic sound components and therefore improve its performance.

--> _replace THIS LINE by your translation for the above line_

> Having more hand-engineered components generally allows a speech system to learn with less data. The hand-engineered knowledge captured by MFCCs and phonemes "supplements" the knowledge our algorithm acquires from data. When we don’t have much data, this knowledge is useful.

--> _replace THIS LINE by your translation for the above line_

> Now, consider the end-to-end system:

--> _replace THIS LINE by your translation for the above line_

![img](../imgs/C49_02.png)

> This system lacks the hand-engineered knowledge. Thus, when the training set is small, it might do worse than the hand-engineered pipeline.

--> _replace THIS LINE by your translation for the above line_

> However, when the training set is large, then it is not hampered by the limitations of an MFCC or phoneme-based representation. If the learning algorithm is a large-enough neural network and if it is trained with enough training data, it has the potential to do very well, and perhaps even approach the optimal error rate.

--> _replace THIS LINE by your translation for the above line_

> End-to-end learning systems tend to do well when there is a lot of labeled data for "both ends"—the input end and the output end. In this example, we require a large dataset of (audio, transcript) pairs. When this type of data is not available, approach end-to-end learning with great caution.

--> _replace THIS LINE by your translation for the above line_

> If you are working on a machine learning problem where the training set is very small, most of your algorithm’s knowledge will have to come from your human insight. I.e., from your "hand engineering" components.

--> _replace THIS LINE by your translation for the above line_

> If you choose not to use an end-to-end system, you will have to decide what are the steps in your pipeline, and how they should plug together. In the next few chapters, we’ll give some suggestions for designing such pipelines.

--> _replace THIS LINE by your translation for the above line_
